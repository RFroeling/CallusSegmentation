{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"CallusSegmentation","text":"<p>A Python toolkit for automated image segmentation of plant callus tissue from Leica LIF microscopy files. It is meant as a tool to automate processes around the PlantSeg segmentation workflow, and specifically designed for the segmentation of callus tissue. </p> <p>This package provides tools for converting multi-scene LIF files to OME-TIFF format, cleaning segmented images, running PlantSeg workflows, and interactively reviewing results.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>LIF to OME-TIFF conversion: Batch convert Leica LIF files with multiple scenes to standardized OME-TIFF format</li> <li>PlantSeg integration: Run deep learning-based segmentation workflows using PlantSeg</li> <li>Image cleaning: Automated post-processing of segmented images with watershed segmentation and edge artifact removal</li> <li>Interactive image review: GUI for reviewing and validating segmentation results</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>This project uses uv for fast dependency management. If you don't have uv installed, install it first:</p> <pre><code>pip install uv\n</code></pre> <p>Then clone the repository and install the package:</p> <pre><code>git clone git@github.com:RFroeling/CallusSegmentation.git\ncd CallusSegmentation\nuv sync\n</code></pre> <p>On Linux with GPU support, PyTorch will be installed with CUDA 12.6. On other platforms (macOS, Windows), CPU-only PyTorch is used.</p>"},{"location":"#configuration","title":"Configuration","text":"<p>Create a <code>.env</code> file in the project root to configure paths for different tasks:</p> <pre><code># For LIF to OME-TIFF conversion\nLIF_PATH=\"/path/to/lif/files\"\nOME_TIFF_PATH=\"/path/to/output/ome-tiff\"\n\n# For edge cleaning\nDATA_PATH=\"/path/to/h5/segmentation/results\"\nKEY=\"H5_uncleaned_dataset_key\"\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<p>The package provides a command-line interface with several subcommands:</p>"},{"location":"#convert-lif-files-to-ome-tiff","title":"Convert LIF files to OME-TIFF","text":"<pre><code>uv run run_segmentation.py --convert\n</code></pre> <p>Removes all LIF files in <code>LIF_PATH</code> (specified in <code>.env</code>) and saves their scenes as separate OME-TIFF files in <code>OME_TIFF_PATH</code>.</p>"},{"location":"#run-plantseg-segmentation","title":"Run PlantSeg segmentation","text":"<pre><code>uv run run_segmentation.py --plantseg path/to/config.yaml\n</code></pre> <p>Execute PlantSeg segmentation workflow using a configuration YAML file. See PlantSeg documentation for configuration details.</p>"},{"location":"#clean-segmentation-edges","title":"Clean segmentation edges","text":"<pre><code>uv run run_segmentation.py --clean\n</code></pre> <p>Post-process segmented images from <code>DATA_PATH</code> to remove edge artifacts using watershed segmentation and connected component analysis. Outputs cleaned H5 files and comparison visualizations.</p>"},{"location":"#interactive-image-review","title":"Interactive Image Review","text":"<pre><code>uv run run_segmentation.py --review\n</code></pre> <p>Launch an interactive GUI for reviewing segmentation results. Use this to validate automated results and identify any artifacts.</p>"},{"location":"#inspect-h5-files","title":"Inspect H5 Files","text":"<pre><code>uv run run_segmentation.py --inspect\n</code></pre> <p>Print the structure and metadata of H5 segmentation files to the console for debugging and verification.</p>"},{"location":"#project-structure","title":"Project Structure","text":"<pre><code>CallusSegmentation/\n\u251c\u2500\u2500 segmentation/                     # Main package\n\u2502   \u251c\u2500\u2500 entry.py                      # CLI entry point\n\u2502   \u251c\u2500\u2500 core/                         # Core utilities\n\u2502   \u2502   \u251c\u2500\u2500 cleaning.py               # Image cleaning functions\n\u2502   \u2502   \u251c\u2500\u2500 io.py                     # File I/O operations\n\u2502   \u2502   \u251c\u2500\u2500 logger.py                 # Logging configuration\n\u2502   \u2502   \u2514\u2500\u2500 views.py                  # Visualization tools\n\u2502   \u2514\u2500\u2500 tasks/                        # Individual workflow tasks\n\u2502       \u251c\u2500\u2500 clean_edges.py            # Edge cleaning workflow\n\u2502       \u251c\u2500\u2500 convert_lif.py            # LIF to OME-TIFF conversion\n\u2502       \u251c\u2500\u2500 inspect_h5.py             # H5 file inspection\n\u2502       \u251c\u2500\u2500 move_files.py             # File management utilities\n\u2502       \u251c\u2500\u2500 review.py                 # Image review interface\n\u2502       \u2514\u2500\u2500 run_plantseg_workflow.py  # PlantSeg integration\n\u251c\u2500\u2500 docs/                             # Documentation\n\u251c\u2500\u2500 run_segmentation.py               # Quick-start entry point\n\u2514\u2500\u2500 pyproject.toml                    # Project configuration &amp; dependencies\n</code></pre>"},{"location":"#dependencies","title":"Dependencies","text":"<ul> <li>plantseg (2.0.0rc12): Deep learning segmentation</li> <li>bioio: General image I/O support</li> <li>bioio-lif &amp; bioio-ome-tiff: Format-specific readers/writers</li> <li>h5py: HDF5 file handling</li> <li>scikit-image: Image processing algorithms</li> <li>torch &amp; torchvision: Deep learning framework</li> <li>numpy, scipy, pandas: Scientific computing</li> <li>matplotlib: Visualization</li> </ul>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Python \u2265 3.13</li> <li>macOS, Linux, or Windows</li> </ul>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the Creative Commons Attribution 4.0 International License.</p>"},{"location":"API/","title":"API reference","text":"<p>The project consists of two hierarchical layers. The first layer <code>core</code> contains the logic for the core functionality. The layer <code>tasks</code> combines elements of the core functionality layer to create tasks.</p>"},{"location":"API/#core","title":"core","text":""},{"location":"API/#io","title":"io","text":"<p>Module that provides functionality to deal with .h5 datasets.</p>"},{"location":"API/#segmentation.core.io.get_h5_files","title":"<code>get_h5_files(folder_path)</code>","text":"<p>Get all .h5 files in a folder.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>Path</code> <p>Path to the folder to search.</p> required <p>Returns:</p> Type Description <code>list[Path]</code> <p>list[Path]: List of .h5 file paths.</p> Source code in <code>segmentation\\core\\io.py</code> <pre><code>def get_h5_files(folder_path: Path) -&gt; list[Path]:\n    \"\"\"Get all .h5 files in a folder.\n\n    Args:\n        folder_path (Path): Path to the folder to search.\n\n    Returns:\n        list[Path]: List of .h5 file paths.\n    \"\"\"\n    h5_files = list(folder_path.glob('*.h5'))\n    return sorted(h5_files)\n</code></pre>"},{"location":"API/#segmentation.core.io.load_h5","title":"<code>load_h5(path, key)</code>","text":"<p>Load a dataset as a numpy array using context manager by given key from a .h5 file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the .h5 file.</p> required <code>key</code> <code>str</code> <p>Key of the dataset to load.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The loaded dataset.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the key doesn't exist in the file.</p> <code>FileNotFoundError</code> <p>If the file doesn't exist.</p> Source code in <code>segmentation\\core\\io.py</code> <pre><code>def load_h5(path: Path, key: str | None) -&gt; np.ndarray:\n    \"\"\"Load a dataset as a numpy array using context manager by given key from a .h5 file.\n\n    Args: \n        path (Path): Path to the .h5 file.\n        key (str): Key of the dataset to load.\n\n    Returns: \n        np.ndarray: The loaded dataset.\n\n    Raises:\n        KeyError: If the key doesn't exist in the file.\n        FileNotFoundError: If the file doesn't exist.\n    \"\"\"\n    if not path.exists():\n        raise FileNotFoundError(f\"File not found: {path}\")\n\n    if key is None or key == \"\":\n        raise ValueError(\"Key is required to load a dataset from a .h5 file\")\n\n    with h5py.File(path, 'r') as f:\n        if key not in f:\n            available_keys = list(f.keys())\n            raise KeyError(f\"Key '{key}' not found in {path.name}. Available keys: {available_keys}\")\n        dataset = np.array(f[key])\n\n    return dataset\n</code></pre>"},{"location":"API/#segmentation.core.io.print_h5_metrics","title":"<code>print_h5_metrics(file_path)</code>","text":"<p>Inspect and print metrics about a .h5 file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path</code> <p>Path to the .h5 file to inspect.</p> required Source code in <code>segmentation\\core\\io.py</code> <pre><code>def print_h5_metrics(file_path: Path) -&gt; None:\n    \"\"\"Inspect and print metrics about a .h5 file.\n\n    Args:\n        file_path (Path): Path to the .h5 file to inspect.\n    \"\"\"\n    # File size\n    file_size_mb = getsize(file_path) / (1024 ** 2)\n\n    print(f\"\\n{'='*60}\")\n    print(f\"File: {file_path.name}\")\n    print(f\"{'='*60}\")\n    print(f\"Path: {file_path}\")\n    print(f\"Size: {file_size_mb:.2f} MB\")\n    print(f\"\\n{'Datasets:':&lt;50}\")\n    print(f\"{'-'*60}\")\n\n    with h5py.File(file_path, 'r') as f:\n        # Print all keys and their properties\n        for key in f.keys():\n            dataset = np.array(f[key])\n            shape = dataset.shape\n            dtype = dataset.dtype\n\n            print(f\"\\nKey: {key}\")\n            print(f\"  Shape: {shape}\")\n            print(f\"  Data type: {dtype}\")\n            print(f\"  Size: {dataset.nbytes / (1024 ** 2):.2f} MB\")\n\n            # Print statistics for numeric datasets\n            if dataset.dtype.kind in ['f', 'i', 'u']:  # float, signed int, unsigned int\n                print(f\"  Min: {dataset[()].min():.4f}\")\n                print(f\"  Max: {dataset[()].max():.4f}\")\n                print(f\"  Mean: {dataset[()].mean():.4f}\")\n\n    print(f\"\\n{'='*60}\\n\")\n</code></pre>"},{"location":"API/#segmentation.core.io.read_h5_voxel_size","title":"<code>read_h5_voxel_size(path, key)</code>","text":"<p>Load the voxel size from a h5 file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>path to the h5 file</p> required <code>key</code> <code>str | None</code> <p>key of the dataset in the h5 file.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Voxel size (ZYX) represented as a numpy array</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If key is not present in .h5 dataset.</p> Source code in <code>segmentation\\core\\io.py</code> <pre><code>def read_h5_voxel_size(\n    path: Path,\n    key: str | None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Load the voxel size from a h5 file.\n\n    Args:\n        path (Path): path to the h5 file\n        key (str | None): key of the dataset in the h5 file.\n\n    Returns:\n        np.ndarray: Voxel size (ZYX) represented as a numpy array\n\n    Raises:\n        ValueError: If key is not present in .h5 dataset.\n    \"\"\"\n    with h5py.File(path, \"r\") as f:\n        data = f[key]\n\n        if not isinstance(data, h5py.Dataset):\n            raise ValueError(f\"'{key}' is not a h5py.Dataset.\")\n\n        voxel_size = data.attrs.get(\"element_size_um\", None)\n\n        if voxel_size is None:\n            logger.warning(f\"Voxel size not found in {path}.\")\n\n    return voxel_size\n</code></pre>"},{"location":"API/#segmentation.core.io.read_lif","title":"<code>read_lif(filename)</code>","text":"<p>Reads a .lif file into a BioImage object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Path</code> <p>Path to the .lif file.</p> required <p>Returns:</p> Name Type Description <code>BioImage</code> <code>BioImage</code> <p>BioImage representation of .lif file</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If provided filetype is not a .lif file.</p> Source code in <code>segmentation\\core\\io.py</code> <pre><code>def read_lif(filename: Path) -&gt; BioImage:\n    \"\"\"Reads a .lif file into a BioImage object.\n\n    Args:\n        filename (Path): Path to the .lif file.\n\n    Returns:\n        BioImage: BioImage representation of .lif file\n\n    Raises:\n        ValueError: If provided filetype is not a .lif file.\n    \"\"\"\n    if filename.suffix != '.lif':\n        raise ValueError(f'Expected a .lif file, got {filename.suffix}')\n\n    return BioImage(filename, reader=bioio_lif.Reader)\n</code></pre>"},{"location":"API/#segmentation.core.io.safe_scenename","title":"<code>safe_scenename(scene)</code>","text":"<p>.lif files taken using navigator functionality might containt slashes in their scenenames, which makes them annoying to save.</p> <p>This function returns a safe scenename that can be used for saving.</p> <p>Parameters:</p> Name Type Description Default <code>scene</code> <code>str</code> <p>Scenename</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Safe scenename</p> Source code in <code>segmentation\\core\\io.py</code> <pre><code>def safe_scenename(scene:str) -&gt; str:\n    \"\"\".lif files taken using navigator functionality might containt slashes in their scenenames, which makes them annoying to save.\n\n    This function returns a safe scenename that can be used for saving.\n\n    Args:\n        scene (str): Scenename\n\n    Returns:\n        str: Safe scenename\n    \"\"\"\n    if '/' in scene:\n        safe_scene = scene.split('/')[-1]\n    elif '\\\\' in scene:\n        safe_scene = scene.split('\\\\')[-1]\n    else:\n        safe_scene = scene\n\n    return safe_scene\n</code></pre>"},{"location":"API/#segmentation.core.io.save_h5","title":"<code>save_h5(path, stack, key, voxel_size, mode='a')</code>","text":"<p>Create a dataset inside a h5 file from a numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>path to the h5 file</p> required <code>stack</code> <code>ndarray</code> <p>numpy array to save as dataset in the h5 file.</p> required <code>key</code> <code>str</code> <p>key of the dataset in the h5 file.</p> required <code>voxel_size</code> <code>ndarray | None</code> <p>voxel size of the dataset.</p> required <code>mode</code> <code>str</code> <p>mode to open the h5 file ['w', 'a'].</p> <code>'a'</code> Source code in <code>segmentation\\core\\io.py</code> <pre><code>def save_h5(path: Path, \n            stack: np.ndarray, \n            key: str | None, \n            voxel_size: np.ndarray | None, \n            mode: str = \"a\"\n    ) -&gt; None:\n    \"\"\"\n    Create a dataset inside a h5 file from a numpy array.\n\n    Args:\n        path (Path): path to the h5 file\n        stack (np.ndarray): numpy array to save as dataset in the h5 file.\n        key (str): key of the dataset in the h5 file.\n        voxel_size (np.ndarray | None): voxel size of the dataset.\n        mode (str): mode to open the h5 file ['w', 'a'].\n\n    \"\"\"\n\n    if key is None:\n        raise ValueError(\"Key is required to create a dataset in a h5 file.\")\n\n    if key == \"\":\n        raise ValueError(\"Key cannot be empty to create a dataset in a h5 file.\")\n\n    with h5py.File(path, mode) as f:\n        if key in f:\n            del f[key]\n        f.create_dataset(key, data=stack, compression=\"gzip\")\n        # save voxel_size\n        if voxel_size is not None:\n            f[key].attrs[\"element_size_um\"] = voxel_size\n</code></pre>"},{"location":"API/#segmentation.core.io.save_scenes_as_ome_tiff","title":"<code>save_scenes_as_ome_tiff(bioimg, output_dir)</code>","text":"<p>Iterates over all scenes in a BioImage object and saves each of them as ome.tiff while preserving physical pixel dimensions.</p> <p>Supports 5D (TCZYX) images, but provides no option to produce subsets. That means that dimensonality in == dimensionality out. When single timepoint and single channel images are required, such as for PlantSeg analysis, they should also be provided as such.</p> <p>Parameters:</p> Name Type Description Default <code>bioimg</code> <code>BioImage</code> <p>BioImage object (image) containing at least 1 scene.</p> required <code>output_dir</code> <code>Path</code> <p>Directory where scenes are stored.</p> required Source code in <code>segmentation\\core\\io.py</code> <pre><code>def save_scenes_as_ome_tiff(bioimg: BioImage, output_dir: Path) -&gt; None:\n    \"\"\"Iterates over all scenes in a BioImage object and saves each of them as ome.tiff\n    while preserving physical pixel dimensions.\n\n    Supports 5D (TCZYX) images, but provides no option to produce subsets. That means that\n    dimensonality in == dimensionality out. When single timepoint and single channel images\n    are required, such as for PlantSeg analysis, they should also be provided as such.\n\n    Args:\n        bioimg (BioImage): BioImage object (image) containing at least 1 scene.\n        output_dir (Path): Directory where scenes are stored.\n    \"\"\"\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    logger.info(f'Found {len(bioimg.scenes)} scenes in BioImage: \\n')\n\n    for i, scene in enumerate(bioimg.scenes):\n        safe_scene = safe_scenename(scene)\n        path = output_dir / f'{safe_scene}.ome.tiff'\n        try:\n            bioimg.save(path, select_scenes=[scene])\n            logger.info(f\"Converted image {i +1}/{len(bioimg.scenes)}: {safe_scene}.ome.tiff\")\n        except Exception as e:\n            logger.error(f\"Unexpected error: {type(e).__name__}: {e} \\n Could not save scene {safe_scene}.\")\n</code></pre>"},{"location":"API/#cleaning","title":"cleaning","text":"<p>Module contains functions for removing unwanted labels in segmentation results.</p>"},{"location":"API/#segmentation.core.cleaning.apply_mask","title":"<code>apply_mask(labels, mask)</code>","text":"<p>Apply a binary mask to the labeled image.</p> <p>Sets all voxels in the labels array to 0 where the corresponding voxel in the mask is False, effectively removing unwanted tissues.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>ndarray</code> <p>Segmentatation output, NumPy array where each cell has a unique integer label.</p> required <code>mask</code> <code>ndarray</code> <p>Binary mask where voxels to keep are True.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Cleaned labeled image with unwanted tissues removed.</p> Source code in <code>segmentation\\core\\cleaning.py</code> <pre><code>def apply_mask(labels: np.ndarray, mask: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Apply a binary mask to the labeled image.\n\n    Sets all voxels in the labels array to 0 where the corresponding voxel\n    in the mask is False, effectively removing unwanted tissues.\n\n    Args:\n        labels (np.ndarray): Segmentatation output, NumPy array where each cell has a unique integer label.\n        mask (np.ndarray): Binary mask where voxels to keep are True.\n\n    Returns:\n        np.ndarray: Cleaned labeled image with unwanted tissues removed.\n    \"\"\"\n    cleaned_labels = labels.copy()\n    cleaned_labels[~mask] = 0\n\n    return cleaned_labels\n</code></pre>"},{"location":"API/#segmentation.core.cleaning.apply_watershed_segmentation","title":"<code>apply_watershed_segmentation(binary, min_distance=4)</code>","text":"<p>Apply watershed segmentation to separate connected tissue regions.</p> <p>Performs a distance transformation on the binary mask, then identifies local maxima using a minumum distance parameter to generate seeds for the watershed algorithm.</p> <p>Adjust the min_distance parameter to control sensitivity in seed detection; a larger value results in  fewer seeds and potentially undersegmenatation, while a smaller value may lead to oversegmentation.</p> <p>Parameters:</p> Name Type Description Default <code>binary</code> <code>ndarray</code> <p>Binary mask of the tissue volume.</p> required <code>min_distance</code> <code>int</code> <p>Minimum distance between local maxima for seed generation.</p> <code>4</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Labeled image where each tissue has a unique integer label.</p> Source code in <code>segmentation\\core\\cleaning.py</code> <pre><code>def apply_watershed_segmentation(binary: np.ndarray, min_distance: int=4) -&gt; np.ndarray:\n    \"\"\"Apply watershed segmentation to separate connected tissue regions.\n\n    Performs a distance transformation on the binary mask, then identifies local maxima\n    using a minumum distance parameter to generate seeds for the watershed algorithm.\n\n    Adjust the min_distance parameter to control sensitivity in seed detection; a larger value results in \n    fewer seeds and potentially undersegmenatation, while a smaller value may lead to oversegmentation.\n\n    Args:\n        binary (np.ndarray): Binary mask of the tissue volume.\n        min_distance (int): Minimum distance between local maxima for seed generation.\n\n    Returns:\n        np.ndarray: Labeled image where each tissue has a unique integer label.\n    \"\"\"\n    dist = ndi.distance_transform_edt(binary)\n\n    # Find coordinates of local maxima\n    coords = peak_local_max(\n        dist,\n        min_distance=min_distance,\n        labels=binary\n    )\n\n    # Create seeds (= local maxima) array for watershed\n    markers = np.zeros_like(binary, dtype=int)\n    for i, c in enumerate(coords, start=1):\n        markers[tuple(c)] = i\n\n    # Apply watershed algorithm\n    tissue_labels = watershed(dist, markers, mask=binary)\n\n    return tissue_labels\n</code></pre>"},{"location":"API/#segmentation.core.cleaning.calculate_border_touch_fraction","title":"<code>calculate_border_touch_fraction(binary, tissues, props)</code>","text":"<p>Calculate the fraction of each tissue that touches the volume boundary.</p> <p>For each tissue region, computes what proportion of its voxels are located on the boundary planes (first/last slices in z, y, x dimensions).</p> <p>Parameters:</p> Name Type Description Default <code>binary</code> <code>ndarray</code> <p>Binary mask of the tissue volume.</p> required <code>tissues</code> <code>ndarray</code> <p>Labeled image where each tissue has a unique integer label.</p> required <code>props</code> <code>DataFrame</code> <p>DataFrame with tissue properties including 'label' column.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Array of touch fractions for each tissue, one value per tissue.</p> Source code in <code>segmentation\\core\\cleaning.py</code> <pre><code>def calculate_border_touch_fraction(binary: np.ndarray, tissues: np.ndarray, props: pd.DataFrame) -&gt; np.ndarray:\n    \"\"\"Calculate the fraction of each tissue that touches the volume boundary.\n\n    For each tissue region, computes what proportion of its voxels are located\n    on the boundary planes (first/last slices in z, y, x dimensions).\n\n    Args:\n        binary (np.ndarray): Binary mask of the tissue volume.\n        tissues (np.ndarray): Labeled image where each tissue has a unique integer label.\n        props (pd.DataFrame): DataFrame with tissue properties including 'label' column.\n\n    Returns:\n        np.ndarray: Array of touch fractions for each tissue, one value per tissue.\n    \"\"\"\n    # Create a mask marking all voxels on the boundary of the volume (z, y, x faces)\n    border = np.zeros_like(binary)\n    border[[0,-1],:,:] = 1  # First and last z-planes\n    border[:,[0,-1],:] = 1  # First and last y-planes\n    border[:,:,[0,-1]] = 1  # First and last x-planes\n\n    # Calculate what fraction of each tissue touches the border\n    touch_frac = []\n    for lab in props[\"label\"]:\n        vox = tissues == lab  # Get all voxels belonging to this tissue\n        # Numerator: count voxels that are both in tissue AND on border\n        # Denominator: count total voxels in tissue\n        touch_frac.append((vox &amp; border).sum() / vox.sum())\n\n    return np.array(touch_frac)\n</code></pre>"},{"location":"API/#segmentation.core.cleaning.calculate_distance_to_center","title":"<code>calculate_distance_to_center(binary, props)</code>","text":"<p>Calculate Euclidean distance from each tissue centroid to the volume center.</p> <p>Computes the 3D distance from each tissue's centroid to the geometric center of the volume using the formula: sqrt((z1-z2)^2 + (y1-y2)^2 + (x1-x2)^2).</p> <p>Parameters:</p> Name Type Description Default <code>binary</code> <code>ndarray</code> <p>Binary mask of the tissue volume.</p> required <code>props</code> <code>DataFrame</code> <p>DataFrame with tissue properties including centroid columns.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Array of distances for each tissue, one value per tissue.</p> Source code in <code>segmentation\\core\\cleaning.py</code> <pre><code>def calculate_distance_to_center(binary: np.ndarray, props: pd.DataFrame) -&gt; np.ndarray:\n    \"\"\"Calculate Euclidean distance from each tissue centroid to the volume center.\n\n    Computes the 3D distance from each tissue's centroid to the geometric center\n    of the volume using the formula: sqrt((z1-z2)^2 + (y1-y2)^2 + (x1-x2)^2).\n\n    Args:\n        binary (np.ndarray): Binary mask of the tissue volume.\n        props (pd.DataFrame): DataFrame with tissue properties including centroid columns.\n\n    Returns:\n        np.ndarray: Array of distances for each tissue, one value per tissue.\n    \"\"\"\n    # Calculate the geometric center of the volume\n    center = np.array(binary.shape) / 2\n    # Compute Euclidean distance from each tissue's centroid to the volume center\n    distances = np.sqrt(\n        (props[\"centroid-0\"] - center[0])**2 +  # z-axis difference squared\n        (props[\"centroid-1\"] - center[1])**2 +  # y-axis difference squared\n        (props[\"centroid-2\"] - center[2])**2    # x-axis difference squared\n    )\n\n    return distances\n</code></pre>"},{"location":"API/#segmentation.core.cleaning.calculate_tissue_properties","title":"<code>calculate_tissue_properties(binary, tissues)</code>","text":"<p>Calculates basic properties for each tissue region.</p> <p>Function returns basic metrics such as label, area, centroid, and bounding box, and more complex metrics like: - Border touch fraction: Proportion of tissue voxels touching volume boundaries. - Distance to center: Euclidean distance from tissue centroid to volume center.</p> <p>Parameters:</p> Name Type Description Default <code>binary</code> <code>ndarray</code> <p>Binary image where foreground voxels are True.</p> required <code>tissues</code> <code>ndarray</code> <p>Labeled image where each tissue has a unique integer label.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame with properties for each tissue.</p> Source code in <code>segmentation\\core\\cleaning.py</code> <pre><code>def calculate_tissue_properties(binary: np.ndarray, tissues: np.ndarray) -&gt; pd.DataFrame:\n    \"\"\"Calculates basic properties for each tissue region.\n\n    Function returns basic metrics such as label, area, centroid, and bounding box,\n    and more complex metrics like:\n    - Border touch fraction: Proportion of tissue voxels touching volume boundaries.\n    - Distance to center: Euclidean distance from tissue centroid to volume center.\n\n    Args:\n        binary (np.ndarray): Binary image where foreground voxels are True.\n        tissues (np.ndarray): Labeled image where each tissue has a unique integer label.\n\n    Returns:\n        pd.DataFrame: DataFrame with properties for each tissue.\n    \"\"\"\n    # Calculate 'standard' region properties\n    props = pd.DataFrame(regionprops_table(\n        tissues,\n        properties=[\n            \"label\",\n            \"area\",\n            \"centroid\",\n            \"bbox\"\n        ]\n    ))\n\n    # Calculate border touch fraction and distance to center\n    props[\"touch_frac\"] = calculate_border_touch_fraction(binary, tissues, props)\n    props[\"dist_center\"] = calculate_distance_to_center(binary, props)\n\n    return props\n</code></pre>"},{"location":"API/#segmentation.core.cleaning.create_mask","title":"<code>create_mask(tissues, main_tissue)</code>","text":"<p>Creates a binary mask for the main tissue.</p> <p>Checks each voxel in the tissues array and marks it as True if it belongs to the main tissue, otherwise marks it as False.</p> <p>Parameters:</p> Name Type Description Default <code>tissues</code> <code>ndarray</code> <p>Labeled image where each tissue has a unique integer label.</p> required <code>main_tissue</code> <code>int</code> <p>Label of the main tissue.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Binary mask where voxels of the main tissue are True.</p> Source code in <code>segmentation\\core\\cleaning.py</code> <pre><code>def create_mask(tissues: np.ndarray, main_tissue: int) -&gt; np.ndarray:\n    \"\"\"Creates a binary mask for the main tissue.\n\n    Checks each voxel in the tissues array and marks it as True if it belongs\n    to the main tissue, otherwise marks it as False.\n\n    Args:\n        tissues (np.ndarray): Labeled image where each tissue has a unique integer label.\n        main_tissue (int): Label of the main tissue.\n\n    Returns:\n        np.ndarray: Binary mask where voxels of the main tissue are True.\n    \"\"\"\n    return tissues == main_tissue\n</code></pre>"},{"location":"API/#segmentation.core.cleaning.determine_main_tissue","title":"<code>determine_main_tissue(props)</code>","text":"<p>Determine the main tissue by calculating a score for each tissue.  The tissue with the lowest score is selected.</p> <p>The score is computed as the sum of the ranks of each tissue in the following criteria: - Area (larger area = better rank) - Distance to center (closer to center = better rank) - Border touch fraction (lower fraction = better rank)</p> <p>Parameters:</p> Name Type Description Default <code>props</code> <code>DataFrame</code> <p>DataFrame with tissue properties.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Label of the main tissue.</p> Source code in <code>segmentation\\core\\cleaning.py</code> <pre><code>def determine_main_tissue(props: pd.DataFrame) -&gt; int:\n    \"\"\"Determine the main tissue by calculating a score for each tissue. \n    The tissue with the lowest score is selected.\n\n    The score is computed as the sum of the ranks of each tissue in the following criteria:\n    - Area (larger area = better rank)\n    - Distance to center (closer to center = better rank)\n    - Border touch fraction (lower fraction = better rank)\n\n    Args:\n        props (pd.DataFrame): DataFrame with tissue properties.\n\n    Returns:\n        int: Label of the main tissue.\n    \"\"\"\n    scored_props = score_tissues(props)\n    main_tissue = scored_props.sort_values(\"score\").iloc[0].label\n\n    return main_tissue\n</code></pre>"},{"location":"API/#segmentation.core.cleaning.get_edge_label_neighbors","title":"<code>get_edge_label_neighbors(dataset, edge_labels, strictness=2)</code>","text":"<p>Identify neighbor labels that should be removed based on surface contact.</p> <p>Collects all labels touching edge-bordering cells and evaluates whether they should be removed based on their surface contact patterns: - If a neighbor touches only edge-bordering labels, mark for removal - If a neighbor touches both edge and non-edge labels, compare surface areas using strictness parameter:   - Remove if: surface_touching_edge &gt; strictness * surface_touching_other   - Keep otherwise</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>ndarray</code> <p>Labeled image where each tissue has a unique integer label.</p> required <code>edge_labels</code> <code>set[int]</code> <p>Set of labels touching the volume boundaries.</p> required <code>strictness</code> <code>float</code> <p>Multiplier for removal threshold. Higher values are more conservative  (fewer labels removed). For example: strictness=1.0 removes if edge contact &gt; other contact, strictness=2.0 removes only if edge contact is more than twice the other contact. Defaults to 2.0 (more conservative).</p> <code>2</code> <p>Returns:</p> Type Description <code>set[int]</code> <p>set[int]: Set of neighbor labels that should be removed.</p> Source code in <code>segmentation\\core\\cleaning.py</code> <pre><code>def get_edge_label_neighbors(dataset: np.ndarray, edge_labels: set[int], strictness: float=2) -&gt; set[int]:\n    \"\"\"Identify neighbor labels that should be removed based on surface contact.\n\n    Collects all labels touching edge-bordering cells and evaluates whether they should\n    be removed based on their surface contact patterns:\n    - If a neighbor touches only edge-bordering labels, mark for removal\n    - If a neighbor touches both edge and non-edge labels, compare surface areas using strictness parameter:\n      - Remove if: surface_touching_edge &gt; strictness * surface_touching_other\n      - Keep otherwise\n\n    Args:\n        dataset (np.ndarray): Labeled image where each tissue has a unique integer label.\n        edge_labels (set[int]): Set of labels touching the volume boundaries.\n        strictness (float): Multiplier for removal threshold. Higher values are more conservative \n            (fewer labels removed). For example: strictness=1.0 removes if edge contact &gt; other contact,\n            strictness=2.0 removes only if edge contact is more than twice the other contact.\n            Defaults to 2.0 (more conservative).\n\n    Returns:\n        set[int]: Set of neighbor labels that should be removed.\n    \"\"\"\n    labels_to_remove = set()\n\n    # Find all neighbors of edge labels by dilating edge regions\n    edge_mask = np.isin(dataset, list(edge_labels))\n    dilated_edge = ndi.binary_dilation(edge_mask)\n    neighbor_labels = set(np.unique(dataset[dilated_edge &amp; (dataset != 0)])) - edge_labels\n\n    for neighbor in neighbor_labels:\n        neighbor_mask = (dataset == neighbor)\n\n        # Count face contacts with edge labels and other labels\n        faces_with_edge = 0\n        faces_with_other = 0\n\n        # Check 6-connected neighbors (faces in 3D)\n        for shift, axis in [((1, 0, 0), 0), ((-1, 0, 0), 0),\n                           ((0, 1, 0), 1), ((0, -1, 0), 1),\n                           ((0, 0, 1), 2), ((0, 0, -1), 2)]:\n            shifted_neighbor = np.roll(neighbor_mask, shift[axis], axis=axis)\n\n            # Count adjacency to edge labels\n            faces_with_edge += (shifted_neighbor &amp; edge_mask).sum()\n\n            # Count adjacency to other non-edge labels\n            other_mask = (dataset != 0) &amp; ~edge_mask &amp; ~neighbor_mask\n            faces_with_other += (shifted_neighbor &amp; other_mask).sum()\n\n        # Remove if only touches edge labels or touches edge more than others\n        if faces_with_other == 0 or faces_with_edge &gt; strictness * faces_with_other:\n            labels_to_remove.add(neighbor)\n\n    return labels_to_remove\n</code></pre>"},{"location":"API/#segmentation.core.cleaning.get_edge_labels","title":"<code>get_edge_labels(dataset)</code>","text":"<p>Identify labels that touch the volume boundaries.</p> <p>Scans the boundary planes (first/last slices in z, y, x dimensions) to find all unique labels present on these edges.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>ndarray</code> <p>Labeled image where each tissue has a unique integer label.</p> required <p>Returns:</p> Type Description <code>set[int]</code> <p>set[int]: Set of labels that touch the volume boundaries.</p> Source code in <code>segmentation\\core\\cleaning.py</code> <pre><code>def get_edge_labels(dataset: np.ndarray) -&gt; set[int]:\n    \"\"\"Identify labels that touch the volume boundaries.\n\n    Scans the boundary planes (first/last slices in z, y, x dimensions)\n    to find all unique labels present on these edges.\n\n    Args:\n        dataset (np.ndarray): Labeled image where each tissue has a unique integer label.\n\n    Returns:\n        set[int]: Set of labels that touch the volume boundaries.\n    \"\"\"\n    edge_labels = set()\n\n    # Check all six faces of the 3D volume\n    edge_labels.update(np.unique(dataset[0, :, :]))      # First z-plane\n    edge_labels.update(np.unique(dataset[-1, :, :]))     # Last z-plane\n    edge_labels.update(np.unique(dataset[:, 0, :]))      # First y-plane\n    edge_labels.update(np.unique(dataset[:, -1, :]))     # Last y-plane\n    edge_labels.update(np.unique(dataset[:, :, 0]))      # First x-plane\n    edge_labels.update(np.unique(dataset[:, :, -1]))     # Last x-plane\n\n    return edge_labels\n</code></pre>"},{"location":"API/#segmentation.core.cleaning.get_recursive_edge_label_neighbors","title":"<code>get_recursive_edge_label_neighbors(dataset, edge_labels, strictness=2)</code>","text":"<p>Recursively identify labels to remove based on proximity to edge labels.</p> <p>Iteratively applies get_edge_label_neighbors, expanding the set of labels to remove by treating previously identified neighbors as new \"edge labels\" in subsequent iterations. Continues until the set of labels to remove no longer changes.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>ndarray</code> <p>Labeled image where each tissue has a unique integer label.</p> required <code>edge_labels</code> <code>set[int]</code> <p>Set of labels touching the volume boundaries.</p> required <code>strictness</code> <code>float</code> <p>Multiplier for removal threshold (see get_edge_label_neighbors). Defaults to 2.0.</p> <code>2</code> <p>Returns:</p> Type Description <code>set[int]</code> <p>set[int]: Set of all labels that should be removed (includes edge labels and their neighbors).</p> Source code in <code>segmentation\\core\\cleaning.py</code> <pre><code>def get_recursive_edge_label_neighbors(dataset: np.ndarray, edge_labels: set[int], strictness: float=2) -&gt; set[int]:\n    \"\"\"Recursively identify labels to remove based on proximity to edge labels.\n\n    Iteratively applies get_edge_label_neighbors, expanding the set of labels to remove\n    by treating previously identified neighbors as new \"edge labels\" in subsequent iterations.\n    Continues until the set of labels to remove no longer changes.\n\n    Args:\n        dataset (np.ndarray): Labeled image where each tissue has a unique integer label.\n        edge_labels (set[int]): Set of labels touching the volume boundaries.\n        strictness (float): Multiplier for removal threshold (see get_edge_label_neighbors).\n            Defaults to 2.0.\n\n    Returns:\n        set[int]: Set of all labels that should be removed (includes edge labels and their neighbors).\n    \"\"\"\n    labels_to_remove = edge_labels.copy()\n\n    while True:\n        # Find neighbors of current labels_to_remove set\n        new_neighbors = get_edge_label_neighbors(dataset, labels_to_remove, strictness)\n\n        # Add newly found neighbors to the removal set\n        updated_labels = labels_to_remove | new_neighbors\n\n        # If the set didn't change, we've reached convergence\n        if updated_labels == labels_to_remove:\n            break\n\n        labels_to_remove = updated_labels\n\n    return labels_to_remove\n</code></pre>"},{"location":"API/#segmentation.core.cleaning.make_binary","title":"<code>make_binary(dataset, threshold=0)</code>","text":"<p>Convert labeled dataset to binary image.</p> <ul> <li>Label = 0: Background</li> <li>Label &gt; 0: Foreground</li> </ul> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>ndarray</code> <p>Labeled image where each cell has a unique integer label.</p> required <code>threshold</code> <code>float</code> <p>Threshold value for binarization. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Binary image where foreground voxels are True, background voxels are False.</p> Source code in <code>segmentation\\core\\cleaning.py</code> <pre><code>def make_binary(dataset: np.ndarray, threshold: float=0) -&gt; np.ndarray:\n    \"\"\"Convert labeled dataset to binary image.\n\n    - Label = 0: Background\n    - Label &gt; 0: Foreground\n\n    Args:\n        dataset (np.ndarray): Labeled image where each cell has a unique integer label.\n        threshold (float, optional): Threshold value for binarization. Defaults to 0.\n\n    Returns:\n        np.ndarray: Binary image where foreground voxels are True, background voxels are False.\n    \"\"\"\n    binary = dataset &gt; threshold\n\n    return binary\n</code></pre>"},{"location":"API/#segmentation.core.cleaning.remove_labels","title":"<code>remove_labels(dataset, labels)</code>","text":"<p>Remove all voxels belonging to labels in the provided set.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>ndarray</code> <p>Labeled image where each tissue has a unique integer label.</p> required <code>labels</code> <code>set[int]</code> <p>Set of label values to remove.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Cleaned labeled image with specified labels removed.</p> Source code in <code>segmentation\\core\\cleaning.py</code> <pre><code>def remove_labels(dataset: np.ndarray, labels: set[int]) -&gt; np.ndarray:\n    \"\"\"Remove all voxels belonging to labels in the provided set.\n\n    Args:\n        dataset (np.ndarray): Labeled image where each tissue has a unique integer label.\n        labels (set[int]): Set of label values to remove.\n\n    Returns:\n        np.ndarray: Cleaned labeled image with specified labels removed.\n    \"\"\"\n    cleaned = dataset.copy()\n\n    for label in labels:\n        if label == 0:  # Skip background\n            continue\n        cleaned[dataset == label] = 0\n\n    return cleaned\n</code></pre>"},{"location":"API/#segmentation.core.cleaning.score_tissues","title":"<code>score_tissues(props)</code>","text":"<p>Calculate a score for each tissue based on multiple criteria.</p> <p>Parameters:</p> Name Type Description Default <code>props</code> <code>DataFrame</code> <p>description</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: description</p> Source code in <code>segmentation\\core\\cleaning.py</code> <pre><code>def score_tissues(props: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Calculate a score for each tissue based on multiple criteria.\n\n    Args:\n        props (pd.DataFrame): _description_\n\n    Returns:\n        pd.DataFrame: _description_\n    \"\"\"\n    props[\"score\"] = (\n    props.area.rank(ascending=False) +\n    props.dist_center.rank() +\n    props.touch_frac.rank()\n    )\n\n    return props\n</code></pre>"},{"location":"API/#views","title":"views","text":"<p>Module containing the neccessary functions for visualization of segmentation cleanups.</p>"},{"location":"API/#segmentation.core.views.ImageReviewer","title":"<code>ImageReviewer</code>","text":"<p>               Bases: <code>Tk</code></p> <p>GUI for checking the quality of segmentation and cleaning of callus tissue.</p> <p>Currently only supports .png images.</p> Source code in <code>segmentation\\core\\views.py</code> <pre><code>class ImageReviewer(tk.Tk):\n    \"\"\"GUI for checking the quality of segmentation and cleaning of callus tissue.\n\n    Currently only supports .png images.\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n        self.title(\"Image Reviewer\")\n        self.geometry(\"700x700\")\n        self.ui_elements()\n        self.state_variables()\n        self.set_icon()\n\n\n    def ui_elements(self):\n        \"\"\"Creates all widgets and binds events.\"\"\"\n\n        # --- Canvas for image display ---\n        self.canvas = tk.Label(self, bg='lightgrey')\n        self.canvas.pack(fill=\"both\", expand=True, padx=5, pady=5)\n\n        # --- Controls frame ---\n        self.controls = tk.Frame(self)\n        self.controls.pack(fill=\"x\", padx=5, pady=5)\n\n        # --- Left: Open Folder button ---\n        self.open_button = tk.Button(\n            self.controls, text=\"Open Folder\", command=self.open_folder\n        )\n        self.open_button.grid(row=0, column=0, sticky=\"w\", padx=5)\n\n        # --- Center: filename label ---\n        self.filename_label = tk.Label(self.controls, text=\"\", anchor=\"center\")\n        self.filename_label.grid(row=0, column=1, sticky=\"ew\", padx=5)\n\n        # --- Right: Accept + Decline horizontal ---\n        right_frame = tk.Frame(self.controls)\n        right_frame.grid(row=0, column=2, sticky=\"e\", padx=5)\n\n        self.accept_button = tk.Button(\n            right_frame, text=\"Accept\", bg=\"lightgreen\",\n            command=lambda: self.sort_file(\"accepted\")\n        )\n        self.decline_button = tk.Button(\n            right_frame, text=\"Decline\", bg=\"tomato\",\n            command=lambda: self.sort_file(\"declined\")\n        )\n\n        # Pack horizontally inside right_frame\n        self.accept_button.pack(side=\"left\", padx=(0,5))\n        self.decline_button.pack(side=\"left\")\n\n        # --- Configure column weights for flexible resizing ---\n        self.controls.columnconfigure(0, weight=1)  # left\n        self.controls.columnconfigure(1, weight=2)  # center (filename label stretches)\n        self.controls.columnconfigure(2, weight=1)  # right\n\n        # --- Progress label below controls ---\n        self.progress_label = tk.Label(self, text=\"No files loaded\")\n        self.progress_label.pack(pady=5)\n\n        # --- Key bindings ---\n        self.bind(\"&lt;a&gt;\", lambda e: self.sort_file(\"accepted\"))\n        self.bind(\"&lt;d&gt;\", lambda e: self.sort_file(\"declined\"))\n        self.bind(\"&lt;A&gt;\", lambda e: self.sort_file(\"accepted\"))\n        self.bind(\"&lt;D&gt;\", lambda e: self.sort_file(\"declined\"))\n\n\n    def state_variables(self):\n        \"\"\"Define empty state variables\"\"\"\n        self.folder = None\n        self.files = []\n        self.all_files = []\n        self.reviewed_files = []\n        self.index = 0\n        self.frames = []\n        self.frame_index = 0\n        self.log_file = None\n        self.df = pd.DataFrame(columns=[\"FileName\", \"Decision\", \"Timestamp\"])\n\n\n    def set_icon(self):\n        parent_dir = Path(__file__).parents[2]\n        icon_path = parent_dir / \"docs\" / \"img\" / \"icon.png\"\n\n        if icon_path.exists():\n            self.iconphoto(False, tk.PhotoImage(file=icon_path))\n\n\n    def open_folder(self):\n        \"\"\"Open folder and prepare files for review\"\"\"\n        folder = filedialog.askdirectory()\n        if not folder:\n            return\n\n        self.folder = Path(folder)\n        self.parent = self.folder.parent\n\n        # Gather all png files in folder\n        all_files = sorted(self.folder.glob('*.png'))\n        self.all_files = all_files\n\n        # Prepare logging dir and file\n        log_dir = self.parent / \"_logs\"\n        log_dir.mkdir(parents=True, exist_ok=True)\n\n        self.log_file = log_dir / \"review_log.csv\"\n\n        reviewed = set()\n        required_cols = [\"FileName\", \"Decision\", \"Timestamp\"]\n\n        # Load existing log if present\n        if self.log_file.exists():\n            try:\n                self.df = pd.read_csv(self.log_file, dtype=str)\n\n                # Ensure columns present\n                for col in required_cols:\n                    if col not in self.df.columns:\n                        self.df[col] = \"\"\n\n                self.df = self.df[required_cols]\n\n                reviewed = set(\n                    self.df[\"FileName\"]\n                    .dropna()\n                    .astype(str)\n                    .tolist()\n                )\n\n            except Exception as e:\n                messagebox.showwarning(\n                    \"Log read error\",\n                    f\"Could not read existing log file:\\n{e}\"\n                )\n\n                self.df = pd.DataFrame(columns=required_cols)\n\n        # Save reviewed file names into separate list\n        self.reviewed_files = sorted(reviewed)\n\n        # Determine new files\n        new_files = [f for f in all_files if f.name not in reviewed]\n\n        # If a log exists and there are new files, ask whether to re-review all or only new ones\n        if reviewed:\n            if new_files:\n                resp = messagebox.askyesno(\n                    \"Existing review log\",\n                    f\"A review log was found with {len(reviewed)} reviewed file(s).\\n\"\n                    f\"{len(new_files)} file(s) are new in the folder.\\n\\n\"\n                    \"Re-review all files? (Yes = all files, No = only new files)\"\n                )\n                if resp:\n                    # Reset log and review all files\n                    self.df = pd.DataFrame(columns=[\"FileName\", \"Decision\", \"Timestamp\"])\n                    try:\n                        self.df.to_csv(self.log_file, index=False)\n                    except Exception as e:\n                        messagebox.showwarning(\n                            \"Log write error\",\n                            f\"Could not reset log file:\\n{e}\"\n                        )\n                    self.files = all_files.copy()\n                else:\n                    # Only review new files, keep existing log\n                    self.files = new_files\n            else:\n                # No new files\n                resp = messagebox.askyesno(\n                    \"No new files\",\n                    \"All files in the folder are already reviewed.\\nDo you want to re-review all files?\"\n                )\n                if resp:\n                    self.df = pd.DataFrame(columns=[\"FileName\", \"Decision\", \"Timestamp\"])\n                    try:\n                        self.df.to_csv(self.log_file, index=False)\n                    except Exception as e:\n                        messagebox.showwarning(\n                            \"Log write error\",\n                            f\"Could not reset log file:\\n{e}\"\n                        )\n                    self.files = all_files.copy()\n                else:\n                    messagebox.showinfo(\n                        \"Nothing to do\",\n                        \"No new files to review.\"\n                    )\n                    return\n        else:\n            # No existing log; create one and review all files\n            self.df = pd.DataFrame(columns=required_cols)\n\n            try:\n                self.df.to_csv(self.log_file, index=False)\n            except Exception as e:\n                messagebox.showwarning(\n                    \"Log create error\",\n                    f\"Could nog create log file:\\n{e}\"\n                )\n\n            self.files = all_files.copy()\n\n        # Start reviewing\n        self.index = 0\n        if not self.files:\n            messagebox.showinfo(\"No files\", \"No image files found in folder\")\n            return\n        self.show_file()\n\n\n    def show_file(self):\n        \"\"\"Function to display current file\"\"\"\n        if self.index &lt; 0 or self.index &gt;= len(self.files):\n            messagebox.showinfo(\"Done\", \"All files reviewed!\")\n            self.progress_label.config(text=\"Review complete\")\n            self.filename_label.config(text=\"\")  # clear filename when done\n            return\n\n        if not self.folder:\n            messagebox.showerror(\"Error\", \"No folder selected\")\n            return\n\n        # Load and display image\n        image_path = self.folder / self.files[self.index]\n        try:\n            # Load image\n            image = Image.open(image_path)\n\n            # Resize to fit canvas while maintaining aspect ratio\n            canvas_width = self.canvas.winfo_width()\n            canvas_height = self.canvas.winfo_height()\n\n            if canvas_width &gt; 1:  # winfo_width returns 1 if widget not yet rendered\n                image.thumbnail((canvas_width - 10, canvas_height - 10), Image.Resampling.LANCZOS)\n\n            # Convert to PhotoImage and display\n            self.photo_image = ImageTk.PhotoImage(image)\n            self.canvas.config(image=self.photo_image)\n\n            # Update labels\n            filename = self.files[self.index].name\n            self.filename_label.config(text=filename)\n            self.update_progress()\n\n        except Exception as e:\n            messagebox.showerror(\"Error\", f\"Could not load image:\\n{e}\")\n            self.index += 1\n            self.show_file()\n\n\n    def sort_file(self, decision):\n        \"\"\" Function to sort file based on user decision\"\"\"\n        if self.log_file:\n            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n            fname = self.files[self.index].name\n            # Update dataframe: if exists, replace; else append\n            if not self.df.empty and fname in self.df[\"FileName\"].values:\n                self.df.loc[self.df[\"FileName\"] == fname, [\"Decision\", \"Timestamp\"]] = [decision, timestamp]\n            else:\n                new_row = {\"FileName\": fname, \"Decision\": decision, \"Timestamp\": timestamp}\n                self.df = pd.concat([self.df, pd.DataFrame([new_row])], ignore_index=True)\n            # Write to disk\n            try:\n                self.df.to_csv(self.log_file, index=False)\n            except Exception as e:\n                messagebox.showwarning(\n                    \"Log write error\",\n                    f\"Could not write to log file:\\n{e}\"\n                )\n\n        # Move to next file\n        self.index += 1\n        if self.index &lt; len(self.files):\n            self.show_file()\n        else:\n            messagebox.showinfo(\"Done\", \"All files reviewed!\")\n            self.canvas.config(image='')\n            self.progress_label.config(text=\"Review complete\")\n            self.filename_label.config(text=\"\")  # clear filename when finished\n\n\n    def update_progress(self):\n        \"\"\"Update progress label\"\"\"\n        total = len(self.files)\n        current = self.index + 1\n        self.progress_label.config(text=f\"Item {current}/{total}\")\n\n    def run(self):\n        self.mainloop()\n</code></pre>"},{"location":"API/#segmentation.core.views.ImageReviewer.open_folder","title":"<code>open_folder()</code>","text":"<p>Open folder and prepare files for review</p> Source code in <code>segmentation\\core\\views.py</code> <pre><code>def open_folder(self):\n    \"\"\"Open folder and prepare files for review\"\"\"\n    folder = filedialog.askdirectory()\n    if not folder:\n        return\n\n    self.folder = Path(folder)\n    self.parent = self.folder.parent\n\n    # Gather all png files in folder\n    all_files = sorted(self.folder.glob('*.png'))\n    self.all_files = all_files\n\n    # Prepare logging dir and file\n    log_dir = self.parent / \"_logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n\n    self.log_file = log_dir / \"review_log.csv\"\n\n    reviewed = set()\n    required_cols = [\"FileName\", \"Decision\", \"Timestamp\"]\n\n    # Load existing log if present\n    if self.log_file.exists():\n        try:\n            self.df = pd.read_csv(self.log_file, dtype=str)\n\n            # Ensure columns present\n            for col in required_cols:\n                if col not in self.df.columns:\n                    self.df[col] = \"\"\n\n            self.df = self.df[required_cols]\n\n            reviewed = set(\n                self.df[\"FileName\"]\n                .dropna()\n                .astype(str)\n                .tolist()\n            )\n\n        except Exception as e:\n            messagebox.showwarning(\n                \"Log read error\",\n                f\"Could not read existing log file:\\n{e}\"\n            )\n\n            self.df = pd.DataFrame(columns=required_cols)\n\n    # Save reviewed file names into separate list\n    self.reviewed_files = sorted(reviewed)\n\n    # Determine new files\n    new_files = [f for f in all_files if f.name not in reviewed]\n\n    # If a log exists and there are new files, ask whether to re-review all or only new ones\n    if reviewed:\n        if new_files:\n            resp = messagebox.askyesno(\n                \"Existing review log\",\n                f\"A review log was found with {len(reviewed)} reviewed file(s).\\n\"\n                f\"{len(new_files)} file(s) are new in the folder.\\n\\n\"\n                \"Re-review all files? (Yes = all files, No = only new files)\"\n            )\n            if resp:\n                # Reset log and review all files\n                self.df = pd.DataFrame(columns=[\"FileName\", \"Decision\", \"Timestamp\"])\n                try:\n                    self.df.to_csv(self.log_file, index=False)\n                except Exception as e:\n                    messagebox.showwarning(\n                        \"Log write error\",\n                        f\"Could not reset log file:\\n{e}\"\n                    )\n                self.files = all_files.copy()\n            else:\n                # Only review new files, keep existing log\n                self.files = new_files\n        else:\n            # No new files\n            resp = messagebox.askyesno(\n                \"No new files\",\n                \"All files in the folder are already reviewed.\\nDo you want to re-review all files?\"\n            )\n            if resp:\n                self.df = pd.DataFrame(columns=[\"FileName\", \"Decision\", \"Timestamp\"])\n                try:\n                    self.df.to_csv(self.log_file, index=False)\n                except Exception as e:\n                    messagebox.showwarning(\n                        \"Log write error\",\n                        f\"Could not reset log file:\\n{e}\"\n                    )\n                self.files = all_files.copy()\n            else:\n                messagebox.showinfo(\n                    \"Nothing to do\",\n                    \"No new files to review.\"\n                )\n                return\n    else:\n        # No existing log; create one and review all files\n        self.df = pd.DataFrame(columns=required_cols)\n\n        try:\n            self.df.to_csv(self.log_file, index=False)\n        except Exception as e:\n            messagebox.showwarning(\n                \"Log create error\",\n                f\"Could nog create log file:\\n{e}\"\n            )\n\n        self.files = all_files.copy()\n\n    # Start reviewing\n    self.index = 0\n    if not self.files:\n        messagebox.showinfo(\"No files\", \"No image files found in folder\")\n        return\n    self.show_file()\n</code></pre>"},{"location":"API/#segmentation.core.views.ImageReviewer.show_file","title":"<code>show_file()</code>","text":"<p>Function to display current file</p> Source code in <code>segmentation\\core\\views.py</code> <pre><code>def show_file(self):\n    \"\"\"Function to display current file\"\"\"\n    if self.index &lt; 0 or self.index &gt;= len(self.files):\n        messagebox.showinfo(\"Done\", \"All files reviewed!\")\n        self.progress_label.config(text=\"Review complete\")\n        self.filename_label.config(text=\"\")  # clear filename when done\n        return\n\n    if not self.folder:\n        messagebox.showerror(\"Error\", \"No folder selected\")\n        return\n\n    # Load and display image\n    image_path = self.folder / self.files[self.index]\n    try:\n        # Load image\n        image = Image.open(image_path)\n\n        # Resize to fit canvas while maintaining aspect ratio\n        canvas_width = self.canvas.winfo_width()\n        canvas_height = self.canvas.winfo_height()\n\n        if canvas_width &gt; 1:  # winfo_width returns 1 if widget not yet rendered\n            image.thumbnail((canvas_width - 10, canvas_height - 10), Image.Resampling.LANCZOS)\n\n        # Convert to PhotoImage and display\n        self.photo_image = ImageTk.PhotoImage(image)\n        self.canvas.config(image=self.photo_image)\n\n        # Update labels\n        filename = self.files[self.index].name\n        self.filename_label.config(text=filename)\n        self.update_progress()\n\n    except Exception as e:\n        messagebox.showerror(\"Error\", f\"Could not load image:\\n{e}\")\n        self.index += 1\n        self.show_file()\n</code></pre>"},{"location":"API/#segmentation.core.views.ImageReviewer.sort_file","title":"<code>sort_file(decision)</code>","text":"<p>Function to sort file based on user decision</p> Source code in <code>segmentation\\core\\views.py</code> <pre><code>def sort_file(self, decision):\n    \"\"\" Function to sort file based on user decision\"\"\"\n    if self.log_file:\n        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        fname = self.files[self.index].name\n        # Update dataframe: if exists, replace; else append\n        if not self.df.empty and fname in self.df[\"FileName\"].values:\n            self.df.loc[self.df[\"FileName\"] == fname, [\"Decision\", \"Timestamp\"]] = [decision, timestamp]\n        else:\n            new_row = {\"FileName\": fname, \"Decision\": decision, \"Timestamp\": timestamp}\n            self.df = pd.concat([self.df, pd.DataFrame([new_row])], ignore_index=True)\n        # Write to disk\n        try:\n            self.df.to_csv(self.log_file, index=False)\n        except Exception as e:\n            messagebox.showwarning(\n                \"Log write error\",\n                f\"Could not write to log file:\\n{e}\"\n            )\n\n    # Move to next file\n    self.index += 1\n    if self.index &lt; len(self.files):\n        self.show_file()\n    else:\n        messagebox.showinfo(\"Done\", \"All files reviewed!\")\n        self.canvas.config(image='')\n        self.progress_label.config(text=\"Review complete\")\n        self.filename_label.config(text=\"\")  # clear filename when finished\n</code></pre>"},{"location":"API/#segmentation.core.views.ImageReviewer.state_variables","title":"<code>state_variables()</code>","text":"<p>Define empty state variables</p> Source code in <code>segmentation\\core\\views.py</code> <pre><code>def state_variables(self):\n    \"\"\"Define empty state variables\"\"\"\n    self.folder = None\n    self.files = []\n    self.all_files = []\n    self.reviewed_files = []\n    self.index = 0\n    self.frames = []\n    self.frame_index = 0\n    self.log_file = None\n    self.df = pd.DataFrame(columns=[\"FileName\", \"Decision\", \"Timestamp\"])\n</code></pre>"},{"location":"API/#segmentation.core.views.ImageReviewer.ui_elements","title":"<code>ui_elements()</code>","text":"<p>Creates all widgets and binds events.</p> Source code in <code>segmentation\\core\\views.py</code> <pre><code>def ui_elements(self):\n    \"\"\"Creates all widgets and binds events.\"\"\"\n\n    # --- Canvas for image display ---\n    self.canvas = tk.Label(self, bg='lightgrey')\n    self.canvas.pack(fill=\"both\", expand=True, padx=5, pady=5)\n\n    # --- Controls frame ---\n    self.controls = tk.Frame(self)\n    self.controls.pack(fill=\"x\", padx=5, pady=5)\n\n    # --- Left: Open Folder button ---\n    self.open_button = tk.Button(\n        self.controls, text=\"Open Folder\", command=self.open_folder\n    )\n    self.open_button.grid(row=0, column=0, sticky=\"w\", padx=5)\n\n    # --- Center: filename label ---\n    self.filename_label = tk.Label(self.controls, text=\"\", anchor=\"center\")\n    self.filename_label.grid(row=0, column=1, sticky=\"ew\", padx=5)\n\n    # --- Right: Accept + Decline horizontal ---\n    right_frame = tk.Frame(self.controls)\n    right_frame.grid(row=0, column=2, sticky=\"e\", padx=5)\n\n    self.accept_button = tk.Button(\n        right_frame, text=\"Accept\", bg=\"lightgreen\",\n        command=lambda: self.sort_file(\"accepted\")\n    )\n    self.decline_button = tk.Button(\n        right_frame, text=\"Decline\", bg=\"tomato\",\n        command=lambda: self.sort_file(\"declined\")\n    )\n\n    # Pack horizontally inside right_frame\n    self.accept_button.pack(side=\"left\", padx=(0,5))\n    self.decline_button.pack(side=\"left\")\n\n    # --- Configure column weights for flexible resizing ---\n    self.controls.columnconfigure(0, weight=1)  # left\n    self.controls.columnconfigure(1, weight=2)  # center (filename label stretches)\n    self.controls.columnconfigure(2, weight=1)  # right\n\n    # --- Progress label below controls ---\n    self.progress_label = tk.Label(self, text=\"No files loaded\")\n    self.progress_label.pack(pady=5)\n\n    # --- Key bindings ---\n    self.bind(\"&lt;a&gt;\", lambda e: self.sort_file(\"accepted\"))\n    self.bind(\"&lt;d&gt;\", lambda e: self.sort_file(\"declined\"))\n    self.bind(\"&lt;A&gt;\", lambda e: self.sort_file(\"accepted\"))\n    self.bind(\"&lt;D&gt;\", lambda e: self.sort_file(\"declined\"))\n</code></pre>"},{"location":"API/#segmentation.core.views.ImageReviewer.update_progress","title":"<code>update_progress()</code>","text":"<p>Update progress label</p> Source code in <code>segmentation\\core\\views.py</code> <pre><code>def update_progress(self):\n    \"\"\"Update progress label\"\"\"\n    total = len(self.files)\n    current = self.index + 1\n    self.progress_label.config(text=f\"Item {current}/{total}\")\n</code></pre>"},{"location":"API/#segmentation.core.views.cleaning_comparison_plot","title":"<code>cleaning_comparison_plot(dataset, cleaned_dataset, path, save=False)</code>","text":"<p>Create comparison plots of original and cleaned datasets.</p> <p>Displays XY and YZ cross-sections of both the original and cleaned datasets side by side for visual comparison.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>ndarray</code> <p>Original dataset.</p> required <code>cleaned_dataset</code> <code>ndarray</code> <p>Cleaned dataset.</p> required <code>path</code> <code>Path</code> <p>Path to the original .h5 file (used for saving plots).</p> required <code>save</code> <code>bool</code> <p>Whether to save the plot as a PNG file. Defaults to False.</p> <code>False</code> Source code in <code>segmentation\\core\\views.py</code> <pre><code>def cleaning_comparison_plot(dataset: np.ndarray, cleaned_dataset: np.ndarray, path: Path, save: bool=False) -&gt; None:\n    \"\"\"Create comparison plots of original and cleaned datasets.\n\n    Displays XY and YZ cross-sections of both the original and cleaned datasets\n    side by side for visual comparison.\n\n    Args:\n        dataset (np.ndarray): Original dataset.\n        cleaned_dataset (np.ndarray): Cleaned dataset.\n        path (Path): Path to the original .h5 file (used for saving plots).\n        save (bool): Whether to save the plot as a PNG file. Defaults to False.\n    \"\"\"\n    _, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n    z = dataset.shape[0] // 2\n    x = dataset.shape[1] // 2\n\n    # Create random colormap for labeled images\n    cmap = create_random_colormap(cleaned_dataset.max() + 1)\n\n    axes[0, 0].imshow(dataset[z], cmap=cmap)\n    axes[0, 0].set_title('Original XY')\n\n    axes[0, 1].imshow(dataset[:, x, :], cmap=cmap)\n    axes[0, 1].set_title('Original YZ')\n\n    axes[1, 0].imshow(cleaned_dataset[z], cmap=cmap)\n    axes[1, 0].set_title('Cleaned XY')\n\n    axes[1, 1].imshow(cleaned_dataset[:, x, :], cmap=cmap)\n    axes[1, 1].set_title('Cleaned YZ')\n\n    if save:\n        import matplotlib as mpl\n        mpl.use('agg') # Non-interactive backend for writing to files\n\n        save_path = path.parent / 'comparison_plots'\n        save_path.mkdir(exist_ok=True)\n        plt.savefig(save_path / f'comparison_{path.stem}.png', dpi=300)\n        plt.close()\n    else:\n        plt.show()\n</code></pre>"},{"location":"API/#segmentation.core.views.create_random_colormap","title":"<code>create_random_colormap(num_labels)</code>","text":"<p>Create a random colormap for labeled images.</p> <p>Generates a colormap where each label gets a unique random color, and the background (label 0) is set to black.</p> <p>Parameters:</p> Name Type Description Default <code>num_labels</code> <code>int</code> <p>Number of unique labels in the image (including background).</p> required <p>Returns:</p> Type Description <code>ListedColormap</code> <p>mcolors.ListedColormap: Colormap with random colors for each label.</p> Source code in <code>segmentation\\core\\views.py</code> <pre><code>def create_random_colormap(num_labels: int) -&gt; mcolors.ListedColormap:\n    \"\"\"Create a random colormap for labeled images.\n\n    Generates a colormap where each label gets a unique random color,\n    and the background (label 0) is set to black.\n\n    Args:\n        num_labels (int): Number of unique labels in the image (including background).\n\n    Returns:\n        mcolors.ListedColormap: Colormap with random colors for each label.\n    \"\"\"\n    # Generate random colors for each label\n    colors = np.random.rand(num_labels, 3)\n\n    # Set the first color (label 0/background) to black\n    colors[0] = [0, 0, 0]\n\n    return mcolors.ListedColormap(colors)\n</code></pre>"},{"location":"API/#meshes","title":"meshes","text":""},{"location":"API/#tasks","title":"tasks","text":""}]}